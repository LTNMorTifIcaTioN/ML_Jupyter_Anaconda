{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **APRENDIZAGEM POR REFORÇO**"
   ],
   "metadata": {
    "id": "zo4_NBVWMQvE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://gym.openai.com/"
   ],
   "metadata": {
    "id": "vxK5jFkXgZt3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://gym.openai.com/envs/Taxi-v3/"
   ],
   "metadata": {
    "id": "zwJaIifT9YtC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Links de referência**"
   ],
   "metadata": {
    "id": "SNKu2HUe9fGW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
   ],
   "metadata": {
    "id": "gJuapuEAMK2m"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://medium.com/turing-talks/aprendizado-por-refor%C3%A7o-4-gym-d18ac1280628"
   ],
   "metadata": {
    "id": "lXmTMZJhML9T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Instalando a Biblioteca GYM**"
   ],
   "metadata": {
    "id": "7swTjEjMHMMl"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1nuOSLFMCbKY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2b3fc123-535b-4b91-81fe-bfa043b0bbed",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:41.553212Z",
     "start_time": "2024-06-05T00:54:39.538236Z"
    }
   },
   "source": [
    "!pip install cmake 'gym[atari]' scipy"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'gym[atari]'\"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import gym"
   ],
   "metadata": {
    "id": "LRh70CdVChvL",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.072966Z",
     "start_time": "2024-06-05T00:54:41.556727Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Carregando e renderizando o ambiente**"
   ],
   "metadata": {
    "id": "I4_DwI5tHbq1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "env = gym.make(\"Taxi-v3\").env"
   ],
   "metadata": {
    "id": "MvgWNK_uCmCK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "22fbee27-fb72-4138-9199-f648844c6511",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.095656Z",
     "start_time": "2024-06-05T00:54:42.074984Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "## Função inoperante devido a inúmeros problemas na execução.\n",
    "## Ela não é essencial para a aprendizagem por reforço, é apenas uma demonstração.\n",
    "## Não retirei do vídeo porque a imagem ajuda no entendimento das ações.\n",
    "# env.render()"
   ],
   "metadata": {
    "id": "JKfP0RINDAfA",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.102769Z",
     "start_time": "2024-06-05T00:54:42.098231Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# redefinindo o ambiente e retornando um estado inicial aleatório.\n",
    "env.reset()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rj2ZuAZDDCR4",
    "outputId": "acb57ba6-cf4b-4036-b38f-cf8bef3fbc8e",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.118338Z",
     "start_time": "2024-06-05T00:54:42.104782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311, {'prob': 1.0, 'action_mask': array([1, 1, 0, 0, 0, 0], dtype=int8)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "## função inoperante\n",
    "# env.render()"
   ],
   "metadata": {
    "id": "0oB2144rDkDe",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.128568Z",
     "start_time": "2024-06-05T00:54:42.123346Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "env.reset: redefine o ambiente e retorna um estado inicial aleatório.\n",
    "\n",
    "env.step(action): Apresenta os passos de ação.\n"
   ],
   "metadata": {
    "id": "LXaShm9SIFDU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Print no espaço de ação discreto e no espaço de estado discreto\n",
    "print(\"Action Space {}\".format(env.action_space))\n",
    "print(\"State Space {}\".format(env.observation_space))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0g-pY7BoDwOu",
    "outputId": "2abe21b9-1bbd-40f6-e431-ec434ceff773",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.138929Z",
     "start_time": "2024-06-05T00:54:42.130582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ESPAÇO DE ESTADO**"
   ],
   "metadata": {
    "id": "E8ovsxyiC-sA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Espaço de estado da grade: 5x5 = 25\n",
    "\n",
    "Espaço posição do passageiro: 5 (quatro pontos externos e um dentro do taxi)\n",
    "\n",
    "Espaço de posição de embargue/desembarque (destino): 4\n",
    "\n",
    "Total: 5x5x5x4 = 500 espaços de estado."
   ],
   "metadata": {
    "id": "ORr0nKOpA9CY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ESPAÇO DE AÇÃO**"
   ],
   "metadata": {
    "id": "eCjLZN58DCy-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O algoritmo escolherá um número de ação de 0 a 5, onde:\n",
    "\n",
    "0 = sul\n",
    "\n",
    "1 = norte\n",
    "\n",
    "2 = leste\n",
    "\n",
    "3 = oeste\n",
    "\n",
    "4 = embarque\n",
    "\n",
    "5 = desembarque"
   ],
   "metadata": {
    "id": "j5C0tVoAJwPp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Colocando o taxi na linha 3, coluna 1, nosso passageiro no local 2 e nosso destino é o local 0.**"
   ],
   "metadata": {
    "id": "gEn_Sq6RK68T"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "state = env.encode(3, 1, 2,0) # (linha do taxi, coluna do taxi, índice do passageiro, índice do destino)\n",
    "print(\"State:\", state)\n",
    "\n",
    "env.s = state\n",
    "#env.render() # função temporariamente inoperante"
   ],
   "metadata": {
    "id": "Wr_-TDSJEgFt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1eea964-cfc4-45d1-ad3c-5d56e8a6ca5f",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.146989Z",
     "start_time": "2024-06-05T00:54:42.140938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Táxi amarelo é sem passageiro e verde é com passageiro.\n",
    "\n",
    "A barra (\"|\") representa uma parede que o táxi não pode atravessar.\n",
    "\n",
    "R, G, Y, B são os possíveis locais de coleta e destino. A **letra azul** representa o local de **embargue** do passageiro e a **letra roxa** é o **desembargue** do passageiro."
   ],
   "metadata": {
    "id": "ywJ13rDjJMbf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recompensas (Já definidas na biblioteca):\n",
    "\n",
    "+20 para um desembarque correto.\n",
    "\n",
    "-10 para um embarque ou desembarque incorreto.\n",
    "\n",
    "-1 para ações que não sejam as duas anteriores."
   ],
   "metadata": {
    "id": "6-cTUWHZKW4U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "env.P[328]"
   ],
   "metadata": {
    "id": "bmWgFuTKEoNj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bd13b218-f4c0-434e-95ec-4527f5f6918e",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.159211Z",
     "start_time": "2024-06-05T00:54:42.149667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output"
   ],
   "metadata": {
    "id": "gSapNw99FFSq",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.166722Z",
     "start_time": "2024-06-05T00:54:42.161222Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "tabela_q = np.zeros([env.observation_space.n, env.action_space.n]) #iniciando a tabela Q"
   ],
   "metadata": {
    "id": "SnRf1JhUFDeR",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.174289Z",
     "start_time": "2024-06-05T00:54:42.168489Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "tabela_q"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLUVMJzb6qXp",
    "outputId": "3188c841-9c29-42f2-d2f5-877b8682a088",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.185022Z",
     "start_time": "2024-06-05T00:54:42.176295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "tabela_q.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14WKyz3w61DI",
    "outputId": "529fecab-0d3b-4efc-9cab-b9e5a8ce5d9d",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:42.195256Z",
     "start_time": "2024-06-05T00:54:42.186539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TREINAMENTO DO ALGORITMO**"
   ],
   "metadata": {
    "id": "CeD6Mkl86VL1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Não existem valores \"certos\" ou \"errados\", é por tentativa e erro.\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1 # Determina a chance do agente tomar uma ação aleatória, nesse caso a chance é de 10%\n",
    "\n",
    "for i in range(1, 200001):\n",
    "    estado = env.reset()\n",
    "\n",
    "    episodios, penalidades, recompensa = 0, 0, 0\n",
    "    terminado = False\n",
    "\n",
    "    while not terminado:\n",
    "        if random.uniform(0, 1) < epsilon: # Decidindo se será tomada uma ação aleatória ou se seguirá a política da tabela-q\n",
    "            acao = env.action_space.sample()\n",
    "        else:\n",
    "            acao = np.argmax(tabela_q[estado])\n",
    "\n",
    "        proximo_estado, recompensa, terminado, info = env.step(acao)\n",
    "\n",
    "        valor_antigo = tabela_q[estado, acao]\n",
    "        proximo_max = np.max(tabela_q[proximo_estado])\n",
    "\n",
    "        # Atualizando o valor de q a partir da equação de Bellman\n",
    "        valor_novo = (1 - alpha) * valor_antigo + alpha * (recompensa + gamma * proximo_max)\n",
    "        tabela_q[estado, acao] = valor_novo # Colocando este valor na tabela-q\n",
    "\n",
    "        if recompensa == -10: # Contabilizando os embarques/desembarques errados\n",
    "            penalidades += 1\n",
    "\n",
    "        estado = proximo_estado\n",
    "        episodios += 1\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episódios: {i}\")\n",
    "\n",
    "print(\"Treinamento terminado.\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUwTuTxgFOU6",
    "outputId": "de962e76-ed64-4c23-8602-866cdbd7b9a4",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:43.279376Z",
     "start_time": "2024-06-05T00:54:42.197270Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m     acao \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39msample()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 16\u001B[0m     acao \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(tabela_q[estado])\n\u001B[0;32m     18\u001B[0m proximo_estado, recompensa, terminado, info \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(acao)\n\u001B[0;32m     20\u001B[0m valor_antigo \u001B[38;5;241m=\u001B[39m tabela_q[estado, acao]\n",
      "\u001B[1;31mIndexError\u001B[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "**AVALIAÇÃO DO ALGORITMO**"
   ],
   "metadata": {
    "id": "XRvVzvzL6k8U"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_penalidades = 0\n",
    "episodios = 100\n",
    "frames = []\n",
    "\n",
    "for i in range(episodios):\n",
    "  estado = env.reset()\n",
    "  penalidades, recompensa = 0, 0\n",
    "  done = False\n",
    "  while not done:\n",
    "    acao = np.argmax(tabela_q[estado])\n",
    "    estado, recompensa, done, info = env.step(acao)\n",
    "\n",
    "    if recompensa == -10:\n",
    "      penalidades += 1\n",
    "\n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': estado,\n",
    "        'action': acao,\n",
    "        'reward': recompensa\n",
    "    })\n",
    "\n",
    "  total_penalidades += penalidades\n",
    "\n",
    "print('Episódios', episodios)\n",
    "print('Penalidades', total_penalidades)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hl4PZe4Q1M0i",
    "outputId": "3674634d-308f-43e4-df59-29b61ee59562",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:43.281383Z",
     "start_time": "2024-06-05T00:54:43.281383Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "for frame in frames:\n",
    "  clear_output(wait=True)\n",
    "  print(frame['frame'])\n",
    "  print('Estado', frame['state'])\n",
    "  print('Ação', frame['action'])\n",
    "  print('Recompensa', frame['reward'])\n",
    "  sleep(.2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZU5Kh861xvp",
    "outputId": "f752cbd5-70ee-4303-f8e8-79675e92e979",
    "ExecuteTime": {
     "end_time": "2024-06-05T00:54:43.284381Z",
     "start_time": "2024-06-05T00:54:43.283383Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
